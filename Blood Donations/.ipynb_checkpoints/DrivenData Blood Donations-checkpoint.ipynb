{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DrivenData - Warm Up: Predict Blood Donations\n",
    "### 1st Entry\n",
    "#### Best Score: 0.4452\n",
    "#### Current Rank: 165/1816 or 91st percentile\n",
    "\n",
    "\n",
    "\n",
    "I use log loss: $$Log Loss = \\frac{1}{N} \\sum_{i=1}^N [y_{i} log , p_{i} + (1 - y_{i}) log , (1 - p_{i})]$$ to evaluate my classifier.\n",
    "\n",
    "$N =$ number of samples\n",
    "\n",
    "$y_{i} =$ binary indicator of whether a donation was made in March 2007 (0 = Did Not Make Donation, 1 = Made Donation)\n",
    "\n",
    "$p_{i} =$ probability of assigning sample i to the correct class\n",
    "\n",
    "\n",
    "Log Loss heavily penalises classifiers that are confident about an incorrect classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Months since Last Donation  Number of Donations  \\\n",
      "619                           2                   50   \n",
      "664                           0                   13   \n",
      "441                           1                   16   \n",
      "160                           2                   20   \n",
      "358                           1                   24   \n",
      "\n",
      "     Total Volume Donated (c.c.)  Months since First Donation  \\\n",
      "619                        12500                           98   \n",
      "664                         3250                           28   \n",
      "441                         4000                           35   \n",
      "160                         5000                           45   \n",
      "358                         6000                           77   \n",
      "\n",
      "     Made Donation in March 2007  \n",
      "619                            1  \n",
      "664                            1  \n",
      "441                            1  \n",
      "160                            1  \n",
      "358                            0  \n",
      "[[    2    50 12500    98]\n",
      " [    0    13  3250    28]\n",
      " [    1    16  4000    35]\n",
      " [    2    20  5000    45]\n",
      " [    1    24  6000    77]]\n",
      "[1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation, neighbors, svm, metrics, tree, linear_model, grid_search, ensemble, naive_bayes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('9db113a1-cdbe-4b1c-98c2-11590f124dd8.csv', index_col = 0)\n",
    "print(df.head())\n",
    "\n",
    "X = np.array(df.drop(['Made Donation in March 2007'], 1))\n",
    "print(X[:5])\n",
    "\n",
    "y = np.array(df['Made Donation in March 2007'])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(X)\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 30, n_jobs=-1)\n",
    "logit = linear_model.LogisticRegression(n_jobs = -1)\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "rf = ensemble.RandomForestClassifier(n_jobs = -1)\n",
    "gnb = naive_bayes.GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def classifier(alg, features, y, k=1):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors = k, n_jobs = -1)\n",
    "\n",
    "    loocv = cross_validation.LeaveOneOut(n) # Create n training and test sets\n",
    "    kfcv = cross_validation.KFold(n, n_folds = 10)\n",
    "    error_rates = [] # Initialize vector of error rate for each iteration of CV\n",
    "    probs = np.empty([0,2]) # Initialize nx2 matrix of prediction probabilities\n",
    "    for train, test in kfcv:\n",
    "        alg.fit(X[train,:], y[train]) # fit algorithm on training set\n",
    "        error = 1 - alg.score(X[test,:], y[test]) # Find the error on the test set\n",
    "        error_rates.append(error) # Create n-vector of error rates\n",
    "        alg_train_pp = alg.predict_proba(X[test,:]) # Calculate prediction probabilities\n",
    "        probs = np.append(probs, alg_train_pp, axis = 0) # Create nx2 matrix of prediction probabilities\n",
    "    #gen_error_rate = sum(error_rates) / n # Gen. error is mean of n error rates in CV\n",
    "    #print('Generalization Error =', gen_error_rate*100, '%')\n",
    "    log_loss = metrics.log_loss(y, probs) # Calculate log-loss\n",
    "    print('Log Loss Score =', log_loss)\n",
    "    \n",
    "    #ROC Curve\n",
    "    #fpr, tpr, thresholds = metrics.roc_curve(y, probs[:,1])\n",
    "    #roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    % matplotlib inline\n",
    "    #fig = plt.plot(fpr, tpr, label='AUC = %0.3f' % roc_auc)\n",
    "    #plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    #plt.xlim([0, 1])\n",
    "    #plt.ylim([0, 1])\n",
    "    #plt.xlabel('False Positive Rate or (1 - Specificity)')\n",
    "    #plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    #plt.title('Receiver Operating Characteristic')\n",
    "    #plt.legend(loc=\"lower right\")\n",
    "    #plt.show()\n",
    "    \n",
    "    #return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss Score = 0.49135502008\n",
      "Log Loss Score = 0.541184301552\n",
      "Log Loss Score = 1.59332566334\n"
     ]
    }
   ],
   "source": [
    "classifier(logit, X, y)\n",
    "classifier(knn, X, y, 40)\n",
    "classifier(rf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('5c9fa979-5a84-45d6-93b9-543d1a0efc41.csv', index_col = 0)\n",
    "X2 = np.array(df2)\n",
    "\n",
    "probability = logit.predict_proba(X2)\n",
    "p = []\n",
    "for i in range(len(X2)):\n",
    "    p.append(probability[i,1])\n",
    "\n",
    "p = pd.DataFrame(p)\n",
    "p['index'] = df2.index\n",
    "p = p[['index', 0]]\n",
    "p.columns = ['', 'Made Donation in March 2007']\n",
    "\n",
    "p.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
