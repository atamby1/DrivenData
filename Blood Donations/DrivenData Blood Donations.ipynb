{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DrivenData - Warm Up: Predict Blood Donations\n",
    "### 1st Entry\n",
    "#### Best Score: 0.4452\n",
    "#### Current Rank: 165/1816 or 91st percentile\n",
    "\n",
    "\n",
    "\n",
    "I use log loss: $$Log Loss = \\frac{1}{N} \\sum_{i=1}^N [y_{i} log , p_{i} + (1 - y_{i}) log , (1 - p_{i})]$$ to evaluate my classifier.\n",
    "\n",
    "$N =$ number of samples\n",
    "\n",
    "$y_{i} =$ binary indicator of whether a donation was made in March 2007 (0 = Did Not Make Donation, 1 = Made Donation)\n",
    "\n",
    "$p_{i} =$ probability of assigning sample i to the correct class\n",
    "\n",
    "\n",
    "Log Loss heavily penalises classifiers that are confident about an incorrect classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Months since Last Donation  Number of Donations  \\\n",
      "619                           2                   50   \n",
      "664                           0                   13   \n",
      "441                           1                   16   \n",
      "160                           2                   20   \n",
      "358                           1                   24   \n",
      "\n",
      "     Total Volume Donated (c.c.)  Months since First Donation  \\\n",
      "619                        12500                           98   \n",
      "664                         3250                           28   \n",
      "441                         4000                           35   \n",
      "160                         5000                           45   \n",
      "358                         6000                           77   \n",
      "\n",
      "     Made Donation in March 2007  \n",
      "619                            1  \n",
      "664                            1  \n",
      "441                            1  \n",
      "160                            1  \n",
      "358                            0  \n",
      "[[    2    50 12500    98]\n",
      " [    0    13  3250    28]\n",
      " [    1    16  4000    35]\n",
      " [    2    20  5000    45]\n",
      " [    1    24  6000    77]]\n",
      "[1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation, neighbors, svm, metrics, tree, linear_model, grid_search, ensemble, naive_bayes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('9db113a1-cdbe-4b1c-98c2-11590f124dd8.csv', index_col = 0)\n",
    "print(df.head())\n",
    "\n",
    "X = np.array(df.drop(['Made Donation in March 2007'], 1))\n",
    "print(X[:5])\n",
    "\n",
    "y = np.array(df['Made Donation in March 2007'])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(X)\n",
    "\n",
    "logit = linear_model.LogisticRegression(n_jobs = -1)\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 30, n_jobs=-1)\n",
    "rf = ensemble.RandomForestClassifier(n_jobs = -1)\n",
    "gbt = ensemble.GradientBoostingClassifier()\n",
    "bag = ensemble.BaggingClassifier(n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def classifier(alg, features, y, k=1):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors = k, n_jobs = -1)\n",
    "\n",
    "    loocv = cross_validation.LeaveOneOut(n) # Create n training and test sets\n",
    "    kfcv = cross_validation.KFold(n, n_folds = 10)\n",
    "    error_rates = [] # Initialize vector of error rate for each iteration of CV\n",
    "    probs = np.empty([0,2]) # Initialize nx2 matrix of prediction probabilities\n",
    "    for train, test in kfcv:\n",
    "        alg.fit(X[train,:], y[train]) # fit algorithm on training set\n",
    "        error = 1 - alg.score(X[test,:], y[test]) # Find the error on the test set\n",
    "        error_rates.append(error) # Create n-vector of error rates\n",
    "        alg_train_pp = alg.predict_proba(X[test,:]) # Calculate prediction probabilities\n",
    "        probs = np.append(probs, alg_train_pp, axis = 0) # Create nx2 matrix of prediction probabilities\n",
    "    #gen_error_rate = sum(error_rates) / n # Gen. error is mean of n error rates in CV\n",
    "    #print('Generalization Error =', gen_error_rate*100, '%')\n",
    "    log_loss = metrics.log_loss(y, probs) # Calculate log-loss\n",
    "    print('Accuracy = ', 1 - error)\n",
    "    print('Log Loss Score =', log_loss)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, probs[:,1])\n",
    "    print('AUC = ', metrics.auc(fpr, tpr))\n",
    "    print()\n",
    "    \n",
    "    #ROC Curve\n",
    "    #fpr, tpr, thresholds = metrics.roc_curve(y, probs[:,1])\n",
    "    #roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    % matplotlib inline\n",
    "    #fig = plt.plot(fpr, tpr, label='AUC = %0.3f' % roc_auc)\n",
    "    #plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    #plt.xlim([0, 1])\n",
    "    #plt.ylim([0, 1])\n",
    "    #plt.xlabel('False Positive Rate or (1 - Specificity)')\n",
    "    #plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    #plt.title('Receiver Operating Characteristic')\n",
    "    #plt.legend(loc=\"lower right\")\n",
    "    #plt.show()\n",
    "    \n",
    "    #return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.929824561404\n",
      "Log Loss Score = 0.49135502008\n",
      "AUC =  0.741942955463\n",
      "\n",
      "Accuracy =  0.929824561404\n",
      "Log Loss Score = 0.541184301552\n",
      "AUC =  0.623254582754\n",
      "\n",
      "Accuracy =  0.894736842105\n",
      "Log Loss Score = 1.62808860195\n",
      "AUC =  0.699159552644\n",
      "\n",
      "Accuracy =  0.912280701754\n",
      "Log Loss Score = 0.529432254586\n",
      "AUC =  0.686834094368\n",
      "\n",
      "Accuracy =  0.877192982456\n",
      "Log Loss Score = 1.93629525458\n",
      "AUC =  0.696628284032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier(logit, X, y)\n",
    "classifier(knn, X, y, 40)\n",
    "classifier(rf, X, y)\n",
    "classifier(gbt, X, y)\n",
    "classifier(bag, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Made Donation in March 2007\n",
      "0    659                     0.451503\n",
      "1    276                     0.090290\n",
      "2    263                     0.298160\n",
      "3    303                     0.291919\n",
      "4     83                     0.490016\n",
      "5    500                     0.737226\n",
      "6    530                     0.325081\n",
      "7    244                     0.122798\n",
      "8    249                     0.017206\n",
      "9    728                     0.073698\n",
      "10   129                     0.159686\n",
      "11   534                     0.137011\n",
      "12   317                     0.263108\n",
      "13   401                     0.298160\n",
      "14   696                     0.290337\n",
      "15   192                     0.163398\n",
      "16   176                     0.216213\n",
      "17   571                     0.418476\n",
      "18   139                     0.065902\n",
      "19   423                     0.297742\n",
      "20   563                     0.403906\n",
      "21    56                     0.307436\n",
      "22   528                     0.352231\n",
      "23   101                     0.298160\n",
      "24   467                     0.257126\n",
      "25   382                     0.297261\n",
      "26   466                     0.336708\n",
      "27   294                     0.122798\n",
      "28   512                     0.303441\n",
      "29   659                     0.451503\n",
      "..   ...                          ...\n",
      "170  131                     0.049018\n",
      "171  405                     0.007748\n",
      "172   82                     0.298160\n",
      "173  643                     0.929581\n",
      "174  156                     0.163207\n",
      "175  617                     0.056661\n",
      "176  574                     0.374075\n",
      "177  272                     0.268064\n",
      "178  613                     0.092810\n",
      "179  545                     0.298160\n",
      "180  685                     0.122798\n",
      "181  570                     0.175770\n",
      "182  537                     0.433902\n",
      "183  691                     0.100813\n",
      "184   85                     0.446275\n",
      "185  483                     0.136976\n",
      "186  455                     0.121452\n",
      "187   93                     0.163398\n",
      "188  744                     0.346592\n",
      "189   33                     0.136976\n",
      "190  321                     0.708724\n",
      "191  523                     0.230824\n",
      "192  426                     0.112779\n",
      "193  196                     0.106867\n",
      "194  301                     0.132618\n",
      "195  103                     0.100813\n",
      "196  224                     0.065658\n",
      "197  454                     0.074498\n",
      "198  585                     0.050502\n",
      "199  154                     0.325079\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('5c9fa979-5a84-45d6-93b9-543d1a0efc41.csv', index_col = 0)\n",
    "X2 = np.array(df2)\n",
    "\n",
    "probability = logit.predict_proba(X2)\n",
    "p = []\n",
    "for i in range(len(X2)):\n",
    "    p.append(probability[i,1])\n",
    "\n",
    "p = pd.DataFrame(p)\n",
    "p['index'] = df2.index\n",
    "p = p[['index', 0]]\n",
    "p.columns = ['', 'Made Donation in March 2007']\n",
    "print(p)\n",
    "#p.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
